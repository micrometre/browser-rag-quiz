# ğŸ§  Browser RAG Quiz

A 100% browser-based RAG (Retrieval-Augmented Generation) quiz application. Run AI models directly in your browser â€” no server required!

[![Transformers.js](https://img.shields.io/badge/Transformers.js-Powered-orange?style=for-the-badge)](https://huggingface.co/docs/transformers.js)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![100% Client-Side](https://img.shields.io/badge/100%25-Client--Side-blue?style=for-the-badge)]()

## âœ¨ Features

- ğŸ”’ **100% Client-Side** â€” All processing happens in your browser. No data leaves your device.
- ğŸš€ **No WebGPU Required** â€” Uses WASM for broad browser compatibility
- ğŸ” **Real RAG Pipeline** â€” Embeds documents, retrieves context, and augments LLM responses
- ğŸ§  **Smart Evaluation** â€” LLM validates answers using retrieved context
- ğŸ’¾ **Model Caching** â€” Models are cached locally after first download
- ğŸ“± **Responsive Design** â€” Works on desktop and mobile
- ğŸ¨ **Dark Theme** â€” Easy on the eyes

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Browser                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Flan-T5     â”‚    â”‚Transformers â”‚    â”‚  In-Memory  â”‚ â”‚
â”‚  â”‚ (Text Gen)  â”‚    â”‚    .js      â”‚    â”‚  Vector     â”‚ â”‚
â”‚  â”‚             â”‚    â”‚ (Embeddings)â”‚    â”‚   Store     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                  â”‚                  â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                            â”‚                            â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                   â”‚   Quiz Engine   â”‚                   â”‚
â”‚                   â”‚  - RAG Retrievalâ”‚                   â”‚
â”‚                   â”‚  - LLM Grading  â”‚                   â”‚
â”‚                   â”‚  - Scoring      â”‚                   â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- Any modern browser (Chrome, Firefox, Edge, Safari)

### Installation

```bash
# Clone the repository
git clone https://github.com/micrometre/web-rag-quiz
cd web-rag-quiz

# Install dependencies
npm install

# Start the development server
npm run dev
```

Open [http://localhost:5173](http://localhost:5173) in your browser.

### Production Build

```bash
npm run build
npm run preview
```

## ğŸ¤– Supported LLM Models

All LLM models are powered by [Transformers.js](https://huggingface.co/docs/transformers.js), running entirely in the browser using ONNX runtime (WASM).

| Model | Model ID | Size | Notes |
|-------|----------|------|-------|
| Flan-T5 Small | `Xenova/flan-t5-small` | ~250MB | **Fastest** - Great for quick responses |
| Flan-T5 Base | `Xenova/flan-t5-base` | ~500MB | Better quality responses |
| LaMini Flan-T5 | `Xenova/LaMini-Flan-T5-248M` | ~250MB | Instruction-tuned variant |

### About Flan-T5

Flan-T5 is a text-to-text model by Google that excels at:
- Question answering
- Text summarization
- Instruction following
- Classification tasks

### Adding More Models

You can add any text2text-generation model from [Hugging Face](https://huggingface.co/models?pipeline_tag=text2text-generation&library=transformers.js). Simply add the model ID to the dropdown in `index.html`.

## ğŸ”§ How It Works

1. **Embedding Model Loads** â€” Transformers.js loads `all-MiniLM-L6-v2` for text embeddings
2. **Knowledge Base Indexed** â€” Educational documents are embedded and stored in a vector store
3. **LLM Loads** â€” Transformers.js loads Flan-T5 for text generation
4. **Quiz Begins** â€” For each question:
   - Relevant context is retrieved from the knowledge base (RAG)
   - You answer the question
   - The LLM evaluates your answer using the retrieved context
   - You receive personalized feedback
5. **Results** â€” The LLM generates a personalized summary of your performance

## ğŸ“š Knowledge Base Topics

The built-in knowledge base covers:
- Python Programming
- Machine Learning & Deep Learning
- Large Language Models (LLMs)
- RAG & Prompt Engineering
- Web Development (HTML, CSS, JavaScript)
- Data Science (Pandas, NumPy)
- Browser AI

You can easily extend the knowledge base by editing `src/knowledgeBase.js`.

## ğŸ“¦ Dependencies

### Core AI Library

| Package | Purpose | Runtime |
|---------|---------|--------|
| [@huggingface/transformers](https://github.com/huggingface/transformers.js) | Embeddings & Text Generation | WASM |

### Transformers.js Details

Transformers.js enables running AI models natively in the browser:
- **ONNX Runtime**: Uses WebAssembly for broad compatibility
- **Model Caching**: Models are cached in browser storage after first download
- **Hugging Face Hub**: Access thousands of pre-converted models
- **No Server Required**: All computation happens client-side

```javascript
// Example Transformers.js usage in this project
import { pipeline } from '@huggingface/transformers';

// Text generation with Flan-T5
const generator = await pipeline('text2text-generation', 'Xenova/flan-t5-small');
const result = await generator('Translate to French: Hello, how are you?');

// Text embeddings
const embedder = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2');
const embeddings = await embedder('Some text to embed');
```

### Build Tools

- [Vite](https://vitejs.dev/) â€” Fast build tool and dev server

## ğŸ—‚ï¸ Project Structure

```
browser-rag-quiz/
â”œâ”€â”€ index.html              # Main HTML with quiz UI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.js             # Quiz application logic
â”‚   â”œâ”€â”€ embeddingService.js # Transformers.js embeddings
â”‚   â”œâ”€â”€ vectorStore.js      # In-memory vector database
â”‚   â”œâ”€â”€ llmService.js       # Transformers.js Flan-T5 wrapper
â”‚   â”œâ”€â”€ knowledgeBase.js    # Quiz content & questions
â”‚   â””â”€â”€ styles.css          # Dark theme styling
â”œâ”€â”€ package.json            # Dependencies
â””â”€â”€ vite.config.js          # Vite config with CORS headers
```

## ğŸ§ª Tested Environment

- **OS:** Ubuntu 24.04 LTS
- **Browser:** Chrome, Firefox, Edge
- **Model:** Flan-T5 Small

## ğŸŒ Browser Compatibility

| Browser | Status |
|---------|--------|
| Chrome | âœ… Supported |
| Firefox | âœ… Supported |
| Edge | âœ… Supported |
| Safari | âœ… Supported |

## ğŸ“„ License

MIT License â€” feel free to use this project for any purpose.


## ğŸ”— Useful Links

- [Transformers.js Documentation](https://huggingface.co/docs/transformers.js)
- [Flan-T5 Models on Hugging Face](https://huggingface.co/models?search=flan-t5)
- [Xenova ONNX Models](https://huggingface.co/Xenova)
- [ONNX Runtime Web](https://onnxruntime.ai/docs/tutorials/web/)

---

Made with ï¸ using [Transformers.js](https://github.com/huggingface/transformers.js)
